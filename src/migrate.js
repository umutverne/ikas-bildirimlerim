import pkg from 'pg';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

const { Pool } = pkg;

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

async function runMigrations() {
  // Only run if DATABASE_URL is set (PostgreSQL mode)
  if (!process.env.DATABASE_URL) {
    console.log('âš ï¸  No DATABASE_URL - Skipping PostgreSQL migrations (SQLite will auto-create tables)');
    return;
  }

  console.log('ðŸ”„ Running PostgreSQL migrations...');

  const pool = new Pool({
    connectionString: process.env.DATABASE_URL,
    ssl: process.env.NODE_ENV === 'production' ? { rejectUnauthorized: false } : false
  });

  try {
    // Read all migration files
    const migrationsDir = path.join(__dirname, '../migrations');
    const files = fs.readdirSync(migrationsDir).filter(f => f.endsWith('.sql')).sort();

    for (const file of files) {
      console.log(`ðŸ“„ Running migration: ${file}`);
      const sql = fs.readFileSync(path.join(migrationsDir, file), 'utf8');
      await pool.query(sql);
      console.log(`âœ… Migration completed: ${file}`);
    }

    console.log('âœ… All migrations completed successfully!');
  } catch (error) {
    console.error('âŒ Migration failed:', error);
    throw error;
  } finally {
    await pool.end();
  }
}

// Run migrations
runMigrations().catch(error => {
  console.error('Fatal error during migration:', error);
  process.exit(1);
});
